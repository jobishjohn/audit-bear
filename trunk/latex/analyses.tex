\section{Analyses}
This section presents a description of our analyses and important findings.
\subsection{Votes Possibly Not Uploaded}
\subsubsection{PEBs Not Uploaded}
This analysis generates a list of PEBs used to collect votes on election day. It warns the user of any PEB, master or non-master, used to close terminal(s), which had their data not uploaded to the election reporting system.  The iVotronic files used by the analysis are: EL152 to search for terminal closing information and votes saved to each PEB and EL68A for PEB upload details.

The South Carolina counties deploy two types of PEBs to each precinct on election day: a Ògreen stripe masterÓ PEB to open and close terminals and Òred stripeÓ PEBs to activate ballots once the iVotronic terminals are opened for voting. The precinct procedures, dictate that a single PEB should be used to open and close all machines at a polling location. Failure to strictly follow this protocol led to problems identified in a recent study~\cite{Buell2011}.  Similar problems were experienced in Miami-Dade County during the 2002 Primary election~\cite{Mazella2002}. In that case, poll workers used two or more PEBs to open and close terminals at their precinct.  As a result, the votes from some machines were not collected on election night.  Election officials were forced to spend several days at the warehouse collecting all PEBs used in the election, printing tapes of every PEB, and uploading the votes from the PEBs that were not transported to election headquarters on election night. This caused a significant delay in the reporting of election results. 

[Document our findings]

This analysis is intended to address the current unavailability of uniform procedures for media upload verification, and to reduce the need for on-the-spot solutions to individual problems that can lead to inaccuracies in election results. Identifying PEBs containing election data which were not uploaded to the cumulative totals will allow election officials to identify and correct those problems during the canvassing process. The information concerning the PEBs not uploaded includes: the serial number of the terminal(s) collected in the PEB(s), the number of votes processed in the terminal(s) and the precinct's name and number. With the detailed information the election officials can gather the missing PEB(s) and recollect votes from terminals not included in the cumulative totals resulting in accuracy of certified totals and voter confidence.

The following are some recommendations for system improvement that would make this type of analysis easier in the future.  It would be useful if the PEBs used to close terminal(s) can upload not only the total votes collected but also the serial number of the terminals it closed. Additionally, it should be possible to import a text file containing the list of iVotronic machines and master PEBs deployed to each polling location.  That list could produce a crosscheck table for verification of iVotronics and PEBs uploaded during election night reporting.

\subsubsection{Machines Not Closed}
[To complete by Wednesday]

\subsection{Incomplete Audit Data}
In order to conduct an accurate audit of an election, the audit data must include everything that was recorded on all voting machines during the election.  One of our analyses checks both the event log and ballot images to see if the appropriate machines are present.  Not only is it important that there are ballot images for every machine with votes cast on it, but we need to verify that there is an equal number of vote cast events and ballot images per machine.  When a machine occurs in the event log with recorded votes cast on it during election day, but does not appear in the ballot images, then there must be data missing from the ballot images file.  The reverse situation reveals the opposite error- the event log is not complete.  

The importance of complete audit data lies in the accuracy of auditing elections.  In South Carolina, one of the few components of the election paper trail are the audit logs; this magnifies the importance of having complete information.  While we can identify missing information from the event log and the ballot images file, we assume the data is complete when conducting our other analyses.  If a county supplies an incomplete log, our tool's results will be less accurate than they would be otherwise.  This is problematic because there is a higher possibility for leaving anomalies undetected; missing votes may not be found and officials may not be able to identify why errors occurred during the election.  

While the audit data is clearly not always complete, there are other cases where it may be nearly impossible to tell if the data is incomplete or not.  For example, if a machine was opened on election day, experienced severe problems, had no votes cast on it, and was not included in the event log, it would be undetectable unless the voting system was altered; the creation of a list of machines used at each precinct would benefit this analysis in addition to detecting possibly missing votes.  In the case that the files are incomplete, we assume it to be a result of uploading vote data into the database at different times.  Because there are two different databases (one for the event log and one for the ballot images), the system allows for new data to be uploaded between the creation of the two files.  If there were one database used for both logs, this would reduce the problem.  On the other hand, if there were just one database, it would be nearly impossible to detect incomplete data.  

[Include table as example of this analysis] [Finding from our analyses here (Florence, etc.)] [Suggestions for officials here].

\subsection{Polling Location Related Analyses}
\subsubsection{Long Lines}
Election officials assign voting machines and polling location supplies based on the number of voters registered in each precinct.  As a result, some polling locations may end up overstocked with equipment, precinct supplies or poll workers while others may lack resources or personnel on election day. Monitoring all the polling places in a large county can be a daunting task. Often, election officials don't have any process in place to monitor polling location usage. South Carolina counties have experienced voting machine bottlenecks during the 2008 and 2010 elections~\cite{Kreitman2010, Slade2008, U2010}.  Those counties can benefit from a tool that can analyze DRE audit data to identify peak times at the precincts.  Our study can infer a steady flow of voters from two iVotronic log files (EL152 and EL155) and produce a report detailing possibly busy timeframes due to the number of voting machines. Such information will assist election officials with the planning of future elections by augmenting voting machines or resources where they may be lacking.

Our tool focuses on lines of voters by detecting heavily used voting terminals. When there are consecutive ballots cast with no time delay in between, we are able to infer that there is a line of voters at the voting machines. 

Once our tool groups the iVotronic units by polling location, based on the information contained in the ballot images report (EL155), it verifies that all of the machines were in use. This analysis also uses an iVotronic time approximation function in addition to a function that finds polling locations that close late. The time approximation function was created because the date and time of iVotronic terminals is set manually and subject to human error; therefore, inaccuracies in the timing of the events identified by the audit log can occur.  This approximation is significant in determining the possibility of long lines at polling locations.  The function that determines which polling locations close late is important because we want to focus only on the precincts that were open past 7 P.M. on election day.

To infer long lines, we focused on the polling locations that stayed opened after 7 P.M. as we could conclude they were busy processing the voters standing in line at that time. Our analysis calculates the time between consecutive votes before 7 P.M.; we keep track of the time that these votes occurred and the time difference between votes.  For all of the consecutive votes after 7 P.M., we only store the time difference between votes.  This data is found per machine, which allows us to match it to its respective polling location.  Then, we organize the time differences into one-hour time windows starting at 7 A.M. until 7 P.M.; all of the after-7 P.M. data was grouped together.  Then, focusing on the polling locations that close very late, we use the two sample Kolmogorov-Smirnov test to determine whether the votes cast in a particular time window come from the same distribution as the after-7 P.M. votes.  The result of the statistical test returns two values; one of them is the p-value, which is the probability that the two sample data have the same distribution.  This p-value helped us establish whether a polling location had long lines at a certain time window.  If the p-value is more than 10\% then we can infer that the polling location possibly had long lines in that time window.

%Fix this part (add a table precinct name, p-value is less than 10%, p-value > 10%), then explain the table.
In Berkeley County, we found that 17 precincts were closed after 7:30 P.M. and decided to run the analysis in these locations to determine when there were long lines.  We will emphasize the top five precincts that close very late.  Our analysis reveals that the first precinct Huger \#26, which closed at 8:43:44 P.M., has higher p-values at 7:00 A.M., 8:00 A.M., 10:00 A.M., 11:00 A.M., 1:00 P.M., 2:00 P.M., 3:00 P.M. and 5:00 P.M..  The minimum p-value is 15.4\% at 2:00 P.M. and the maximum is 66.0\% at 11:00 A.M.  Precinct Cordesville \#10 could possibly have had long lines throughout almost the entire day, except for 7:00 A.M. and 12:00 P.M. with a minimum p-value of 13.6\% at 10:00 A.M. and the rest of the time had p-values higher than 20\%.  Precincts Hilton Cross Rd \#24, and Hanahan 1 \#20 also had long lines almost all day.  Precinct Hanahan 3 \#22 only experienced long lines at 5:00 P.M. with a p-value of 38.5\%.  We can conclude that these precincts have experienced long lines during the whole day and it may be the reason for which those precincts closed very late.

We strongly recommend election officials to conduct this analysis after each election to plan for future elections of the same type. Assigning additional personnel, whether poll workers or rovers, and machines to the busy polling locations may reduce long lines of voters.  Our analysis can detect when there is a steady flow of voters, but it does not determine if the long line of voters is caused by a slow registration process or too few voting machines.

\subsubsection{Polling Locations That Closed Late}
[To complete by Wednesday].

\subsection{Hardware Issues}
Election officials may be interested in identifying machines that have hardware problems, such as screen calibration issues, machines with a low battery, terminals that closed early, and machines that recorded unknown, but possibly severe events.  The first of these analyses detects machines with recurring calibration errors and machines that had recorded votes while possibly not calibrated.  By finding the events that correspond to a screen that is not calibrated and to the recalibration of that screen, we can find if votes were cast in between those times.  The second analysis regarding hardware issues looks for machines with an unusually large number of events titled \textquotedblleft Terminal shutdown - IPS Exit\textquotedblright .  We infer that these machines have a low battery because they experience a more-than-normal number of events related to the Internal Power Supply.  Additionally, our tool searches for machines that recorded a warning event about the terminal closing early.  In order for this event to occur, a trained technician must enter a password to access the service menu and make a particular selection to close the machine.  If a machine is closed in this manner during election day, there must be something wrong with it that is preventing votes from being cast correctly.  Lastly, there is a set of events that have questionable meanings, but could potentially represent hardware issues.  

Analyses such as these can help officials identify machines that may require maintenance or to be replaced.  In the case of a machine having ballots cast on it when it is not calibrated, it may not have captured the voter's intent.  Depending on the magnitude of the situation, this could cause a different outcome in the election.  If our analyses detect other hardware problems with a machine, it may not be recording votes accurately; these votes may not even appear in the event log or ballot images.  If the event log and the ballot images do not record ballots being cast, then it is nearly impossible for officials to realize votes are not being counted.  

Due to the available resources and the nature of these analyses, assumptions were made regarding the meaning of events and the severity of the situation.  Currently, there is no user manual or detailed description of the events that appear in the event log; because of this, we are not able to guarantee that the event \textquotedblleft Terminal shutdown - IPS Exit\textquotedblright means the machine has a low battery.  This assumption is also applicable to our calibration analysis and our detection of unknown warning events.  If a description of each event was available, we could be more definitive in our results and possibly implement analyses that report other useful hardware failures.    

[Statistics from reports here] [Suggestions/corrective actions to take].  
 

\subsection{Procedural Errors}
Our tool can detect procedural errors and poll worker mistakes; a few of these are: precincts that do not print zero tapes on the morning of election day, using a master PEB to activate ballots, opening and closing machines with different PEB.  According to the South Carolina poll worker training video (citation), poll workers are required to print at least one zero tape per polling location on the morning of the election.  Using the event log, our tool checks each polling location for this event and reports the locations that did not record this event.  Another way our tool finds procedural errors is by crosschecking the master PEBs with the PEBs used to activate ballots.  Poll workers should be using non-master PEBs to activate ballots so that the PEBs do not get switched.  Along the same lines, we report incidents of opening and closing a machine with different PEBs.  A machine should be opened and closed with the same master PEB; if not, it may be more likely that this PEB does not get uploaded.   When poll workers cancel ballots, they must select a reason why; this is another way to detect errors.  There are seven options for canceling a ballot: wrong ballot, voter left after the ballot was issued, voter left before the ballot was issued, voter request, printer problem, terminal problem, or an unspecified reason.  If there are any instances of canceling a ballot due to a printer problem, it could be an indicator of a procedural error because ballots are not printed.  In other cases, if there is a large number of a specific reason, such as having the wrong ballot, this could indicate the poll workers are repeatedly issuing the wrong ballot.  

It may be beneficial to election officials if they could detect which locations poll workers are following the required procedures in order to mitigate larger problems.  If election officials are aware of the procedures that are not being followed, they will hopefully be able to mitigate them.  This will allow for more efficient audits as well as a better voting experience for voters.  Procedural errors can cause many problems including lost votes, incorrect vote counts, disgruntled voters, and long lines.

While our analyses detect an important set of errors, there are certainly many more procedures that can be analyzed.  In addition to printing zero tapes in the morning, poll workers are required to print results tapes at the end of the election; unfortunately, this is not detectable due to the way the event log is produced.  We have inferred from the event logs that the poll workers are extracting the compact flashes before printing the results tapes, therefore the event log shows no record of the event.  

[Statistics from reports here] [Suggestions/corrective actions to take].

\subsection{Systematic Date and Time Errors}
The iVotronic DREs append each audit event in chronological order.  Each event is marked with a time-stamp based on the DRE's internal clock.  We discovered and report on a variety of errors by classifying the type of errors experienced. Correct time-stamps are critical in post election audits and often incorrect stamps can not be automatically corrected post election.  Previous works identify and remark on some of these date errors~\cite{Buell2011,Sandler2007}.  We further attempt to classify and automate the identification of these issues.

Erroneous time-stamps can invalidate the audit-logs and often preclude data from being used in automated reports.  Determining machines to have either valid or invalid time-stamps has a lot of gray area and different errors will affect different analyses.  Some machines experienced time-stamps that would blank to \textquoteleft 00/00/00 00:00:00' for only a couple of events.  This naturally wouldn't affect data looking at opening and closing times, but would create outliers or gaps in data measuring time between votes cast.  

We found it simplest to classify date errors into two categories.  Those errors resulting from machines not having their clocks set appropriately and those resulting from apparent bugs in the iVotronic time-stamp mechanism itself.  Our website includes an automated a report that attempts to identify and group as many of these errors as possible.

First, machines shipped or set with incorrect dates were identified.  These errors all suggest the need for a more thorough pre-election check of each machine's clock.   Any machines experiencing manual clock adjustments on election day were included in the report as well as those machines which opened for voting on a date that was wildly incorrect (i.e. dates well before pre-election or dates after election day). This mostly included machines that did not account for Daylight Saving Time or  those machines that didn't set their initial date until after opening for voting.  All the above machines were checked as closing on a valid election day.  Pre-voting dates were not considered as they appeared to be inconsistent among the different counties. Machines which open and close on an improbable dates are separately identified as machines that had bad dates that went uncorrected..  

Machines experiencing additional date errors were classified in a separate report.  Many machines were found to have anomalous date changes that weren't paired with the normal date set event. [Figure 1 will show the 4/12 jump in Berkeley county] Often before the clock on a machine is first set the dates will show up as being many years into the future or as a zero date.  This isn't a problem as most  of these machines are set correctly before being opened for voting.  However, there are many places in the logs were the date will seemingly randomly jump to a date far into the future or the past and remain there until manually corrected.  [Figure 2 12\/21 in Berk County] shows a case where the date jumps ahead to 12/21/2010 for two events before changing back.  These machines were automatically identified by looking for any major date jumps that occur on election day or zero stamps being recorded after machines are open. Machines experiencing many date jumps may require troubleshooting from ES\&S.  It may be a more systematic issue that the date on an iVotronic can apparently change for no reason.

We strongly advise that procedures for setting the clocks on machines are reviewed.  The unknown date jumps seen in the logs are concerning, but generally are not creating as many audit issues compared to machines whose date were never set correctly.

Accurate clocks directly impact the usefulness and correctness of the audit logs. Ensuring that every single machine is set correctly is not necessarily a simple task.  We would recommend that each machine is configured accurately before being sent to the precincts.  Additionally, all machines should be double checked for a correct time before opening for voting.  Daylight Saving Time settings are also potential concern.  Many machines (statistic for anderson) were found to be adjusted forward by an hour during election day.  

The Authors of \textquotedblleft Casting Votes in the Auditorium\textquotedblright~\cite{Sandler2007} propose a distributed network between DREs.  This \textquoteleft Auditorium\textquoteright provides a far more robust system to ensure accurate and verifiable audit logs.  They propose a system where all the election machines are networked together and append to a common audit log verified by each machine.  This allows for more error redundancy and removes the logistical issue involved in making sure every single machine has their date correctly set.
