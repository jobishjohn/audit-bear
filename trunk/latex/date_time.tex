\subsection{Systematic Date and Time Errors}\label{an:date} 
Correct time-stamps are critical in post election audits as they can preclude further log analysis. The data set used for this work was found to include many erroneous time-stamps. We found it simplest to classify these date errors into two categories: errors resulting from incorrectly set clocks and errors resulting from apparent bugs in the iVotronic time-stamp mechanism itself. Our website includes a report for each category and automatically identifies as many as these errors as possible while avoiding false positives.  

\subsubsection{Motivation for Detection}
The first report identifies any machine determined to open for election day voting with a incorrect clock.  This means the opening event and possibly all vote events were recorded with incorrect time-stamps. This can prevent other analyses from properly detecting how long the polls stayed open, whether they opened on time, or experienced long lines. Additionally, machines with clocks only slightly inaccurate could have their time stamps adjusted for other analyses by looking at manual difference of the manual correction. It may be useful for an election official to identify counties or precincts where these errors were particularly common so that pre-election testing procedures can be improved.

The second report identifies anomalies in the time stamps that aren't a result of human error. We found many dates that changed seemingly at random and without a manual date adjustment event. These occurrences suggest an issue with the specific machine firmware or the software itself. The cause of these errors remain unknown and can potentially invalidate other audit statistics. It is concerning that these set values can change arbitrarily. Reporting these anomalies may assist those offcials in determining which machines have consistant date issues or in reporting the issue to the DRE vendor.

\subsubsection{Background}
The iVotronic DREs append each audit event to the log in chronological order.  Each event is marked with a time-stamp based on the DRE's internal clock. Each DRE's clock is manually set by election officials or the iVotronic vendors. Any manual adjustments made to the clock are recorded on the audit log. Time-stamps should only change to reflect the passing of time unless the clock is manually set. The report that is generated to detect and classify date errors is specific to the iVotronic audit logs.  However, the process could be applied to other logs assuming they maintain similar properties.  

Determining the accuracy of time-stamps during a post-election audit can have a lot of ambiguities. If a machine has its clocks set an hour back it is difficult to determine if it opened early or if its clock is incorrectly set. Furthermore, those machines opened for early voting are not consistent in which days they open or how long they stay open for. For this reason, many of these reports do not consider date errors based off of events occurring in the early voting time window.

Emphasis was placed on the accurate identification of date errors rather then complete identification. False positives create excessive data for those using our tool to sort through.

\subsubsection{Algorithm}
The date errors are logically classified into two separate reports. However, the first report contains two separate tables so there are actually three different categories of date errors that are identified.  All data was collected by sequentially parsing each time-stamp while keeping track of state. State was determined by looking at events such as the terminal being opened for voting. Only the last set of openings and closings were considered for each machine. This helped ensure we were looking at election day statistics.

The first category identified machines that had their clocks adjusted during election day voting. Since this was a common event it was deemed worthwhile to only highlight machines that had this change during election day itself and not those machines whose clock was adjusted sometime during the early voting period.  Two criteria was created for this list to avoid listing machines with changes during early voting.  The first criteria caught machines who were only off by a couple hours.  We know only because an official bothered to change the clock during election day. The algorithm looked for a manual time change event for any machine that was in an open state during election day.  If the machine then closed successfully on election day, the delta of the time change is recorded and factored into the opening time for other analyses.  

Figure 1 shows an example of a 1 hour time change for the Georgetown county.  This county had 125 out of 140 machines adjusted nearly exactly one hour back in time.  This is presumably because DST was not considered when the machines were first set.

The second criteria simply looked for machines who open on an improbable date but still close on election day.  This included opening on days past election day or days far enough in the past so that early voting openings were not recorded. The days for early voting was determined by trial and error as there was inconsistancy among the different counties as to how many days in advance of election day the earlyvoting started.

The second category found machines that opened on incorrect dates for voting but never had there clocks adjusted correctly.  In the first category clocks that were only slightly off were only detected because someone changed the date during elections.  This couldn't be detected if it was never fixed so this category found dates that opened and closed on improbable dates.  This means dates a month or so before election day and any dates 1 or more days after election day.

The third category focused on detecting anomalies among the time-stamps.  Events are appended in chronological order; any time-stamp that decreases chronologically without a manually date adjustment event is wrong and added to this category. Figure 2 displays an example of this.  Forward jumps in time are not necessarily the result of an inconsistent time record.  A machine can be shut down for weeks between events.  Given the relatively short duration of elections, jumps forward in time far that are past a certain threshold can reasonably be considered bogus.  This algorithm looked for any deltas between time-stamps that jump forward by more then 33 days.  This is arbitrary but upon inspection of the 2010 South Carolina Data set, this seemed to avoid ambiguous jumps.  Additionally, some machines were found to have their clock set to some type of null state where the clock stopped incremented and all the time-stamps were marked as a zero date.  Figure 3 is an example from X county.

Once one of these 'jumps' or anomaly is detected, the previous  time-stamp is marked  as the start and a counter increments on each subsequent event.  The counter ends and the anomaly is assumed to have ended based on criteria for each type of jump. The backward jump is presumed over if an event appears that is chronologically forward in time compared to the start event.  The forward jump is assumed over if an event appears on the same day of the starting event.  The zero clock anomaly is marked as over once a non zero date appears. The number of events associated with an anomaly is reported as well as the anomalous date and machine serial number. 


[Georgetown has a million 1 hour changes – Fig 1]
[Backward Date Jump – Fig 2]
[Zero date – Fig 3]
[Figure 4- Example Report?]
